{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unlabeled_train = pd.read_csv('../../Dataset/Bag Of Words/unlabeledTrainData.tsv',delimiter='\\t',header=0,quoting=3)\n",
    "labeled_train = pd.read_csv('../../Dataset/Bag Of Words/labeledTrainData.tsv',delimiter='\\t',header=0,quoting=3)\n",
    "test = pd.read_csv('../../Dataset/Bag Of Words/testData.tsv',delimiter='\\t',header=0,quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"9999_0\"</td>\n",
       "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"45057_0\"</td>\n",
       "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"15561_0\"</td>\n",
       "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7161_0\"</td>\n",
       "      <td>\"I went to see this film with a great deal of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"43971_0\"</td>\n",
       "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                             review\n",
       "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
       "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
       "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
       "3   \"7161_0\"  \"I went to see this film with a great deal of ...\n",
       "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "def convert_to_wordlist(review,remove_stopwords = False):\n",
    "    ## Removing the HTML\n",
    "    clean_review = BeautifulSoup(review).get_text()\n",
    "    ## Removing Non Letters\n",
    "    clean_review = re.sub('[^a-zA-Z]',\" \",clean_review)\n",
    "    ## Converting to lowercase\n",
    "    clean_review = clean_review.lower()\n",
    "    ## Removing stopwords (if required)\n",
    "    if remove_stopwords:\n",
    "        words = [word for word in clean_review.split() if word not in stopwords.words(\"english\")]\n",
    "    else:\n",
    "        words = clean_review.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def convert_to_sentlist(corpus,remove_stopwords=False):\n",
    "    sentlist = []\n",
    "    tokens = tokenizer.tokenize(corpus.strip())\n",
    "    for token in tokens:\n",
    "        sentlist.append(convert_to_wordlist(token,remove_stopwords))\n",
    "    return sentlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing and Converting reviews to required format..\n",
      "0 reviews parsed...\n",
      "1000 reviews parsed...\n",
      "2000 reviews parsed...\n",
      "3000 reviews parsed...\n",
      "4000 reviews parsed...\n",
      "5000 reviews parsed...\n",
      "6000 reviews parsed...\n",
      "7000 reviews parsed...\n",
      "8000 reviews parsed...\n",
      "9000 reviews parsed...\n",
      "10000 reviews parsed...\n",
      "11000 reviews parsed...\n",
      "12000 reviews parsed...\n",
      "13000 reviews parsed...\n",
      "14000 reviews parsed...\n",
      "15000 reviews parsed...\n",
      "16000 reviews parsed...\n",
      "17000 reviews parsed...\n",
      "18000 reviews parsed...\n",
      "19000 reviews parsed...\n",
      "20000 reviews parsed...\n",
      "21000 reviews parsed...\n",
      "22000 reviews parsed...\n",
      "23000 reviews parsed...\n",
      "24000 reviews parsed...\n",
      "25000 reviews parsed...\n",
      "26000 reviews parsed...\n",
      "27000 reviews parsed...\n",
      "28000 reviews parsed...\n",
      "29000 reviews parsed...\n",
      "30000 reviews parsed...\n",
      "31000 reviews parsed...\n",
      "32000 reviews parsed...\n",
      "33000 reviews parsed...\n",
      "34000 reviews parsed...\n",
      "35000 reviews parsed...\n",
      "36000 reviews parsed...\n",
      "37000 reviews parsed...\n",
      "38000 reviews parsed...\n",
      "39000 reviews parsed...\n",
      "40000 reviews parsed...\n",
      "41000 reviews parsed...\n",
      "42000 reviews parsed...\n",
      "43000 reviews parsed...\n",
      "44000 reviews parsed...\n",
      "45000 reviews parsed...\n",
      "46000 reviews parsed...\n",
      "47000 reviews parsed...\n",
      "48000 reviews parsed...\n",
      "49000 reviews parsed...\n"
     ]
    }
   ],
   "source": [
    "i,sentences = 0,[]\n",
    "print 'Parsing and Converting reviews to required format..'\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += convert_to_sentlist(review.decode('utf-8'))\n",
    "    if i % 1000 == 0:\n",
    "        print '{} reviews parsed...'.format(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300                        \n",
    "min_word_count = 40                        \n",
    "num_workers = 4 \n",
    "context = 10                                                                                    \n",
    "downsampling = 1e-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model....\n"
     ]
    }
   ],
   "source": [
    "print 'Training Model....'\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers,size=num_features, min_count = min_word_count,\\\n",
    "                 window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"Word2Vec\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.6530873775482178),\n",
       " (u'lady', 0.6034382581710815),\n",
       " (u'lad', 0.5575274229049683),\n",
       " (u'person', 0.5470916628837585),\n",
       " (u'men', 0.5238733291625977),\n",
       " (u'guy', 0.5228787064552307),\n",
       " (u'doctor', 0.5218369960784912),\n",
       " (u'boy', 0.5167871713638306),\n",
       " (u'chap', 0.5134159326553345),\n",
       " (u'soldier', 0.5076248645782471)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'princess', 0.6886675357818604),\n",
       " (u'belle', 0.6561340093612671),\n",
       " (u'bride', 0.6472404599189758),\n",
       " (u'maid', 0.6402115225791931),\n",
       " (u'rose', 0.6379253268241882),\n",
       " (u'eva', 0.6294335126876831),\n",
       " (u'catherine', 0.6195963621139526),\n",
       " (u'goddess', 0.6193024516105652),\n",
       " (u'regina', 0.6125284433364868),\n",
       " (u'maria', 0.6090396642684937)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(13056, 300)\n"
     ]
    }
   ],
   "source": [
    "## Syn0 contains each of the vector representation of the words in the vocabulary\n",
    "print type(model.syn0)\n",
    "print model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "## Accessing the word vector for man\n",
    "print model[\"man\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(model,words,num_features=300):\n",
    "    index2word_set = set(model.index2word)\n",
    "    featureVec = np.zeros((num_features,))\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    featureVec = np.divide(featureVec,n_words)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = convert_to_wordlist(unlabeled_train['review'][0],remove_stopwords=True)\n",
    "makeFeatureVec(model,words).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 reviews parsed....\n",
      "2000 reviews parsed....\n",
      "3000 reviews parsed....\n",
      "4000 reviews parsed....\n",
      "5000 reviews parsed....\n",
      "6000 reviews parsed....\n",
      "7000 reviews parsed....\n",
      "8000 reviews parsed....\n",
      "9000 reviews parsed....\n",
      "10000 reviews parsed....\n",
      "11000 reviews parsed....\n",
      "12000 reviews parsed....\n",
      "13000 reviews parsed....\n",
      "14000 reviews parsed....\n",
      "15000 reviews parsed....\n",
      "16000 reviews parsed....\n",
      "17000 reviews parsed....\n",
      "18000 reviews parsed....\n",
      "19000 reviews parsed....\n",
      "20000 reviews parsed....\n",
      "21000 reviews parsed....\n",
      "22000 reviews parsed....\n",
      "23000 reviews parsed....\n",
      "24000 reviews parsed....\n",
      "25000 reviews parsed....\n"
     ]
    }
   ],
   "source": [
    "i,training_data = 0,np.zeros((len(labeled_train[\"review\"]),num_features),dtype=\"float32\")\n",
    "for review in labeled_train[\"review\"]:\n",
    "    words = convert_to_wordlist(review,remove_stopwords=True)\n",
    "    training_data[i] = makeFeatureVec(model,words)\n",
    "    i += 1\n",
    "    if i%1000 == 0:\n",
    "        print '{} reviews parsed....'.format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(training_data).to_csv('trainingdata.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Applying Random Forest Classifier on the dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "score = cross_val_score(rfc,training_data,labeled_train[\"sentiment\"],cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold CV score: 82.304\n"
     ]
    }
   ],
   "source": [
    "print '5 fold CV score: {}'.format(score.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KMeans Clustering to find clusters of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = training_data.shape[0]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "clusters = kmeans.fit_predict(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(clusters).to_csv('clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
