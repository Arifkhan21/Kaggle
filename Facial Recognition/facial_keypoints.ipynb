{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Keypoints Recognition\n",
    "## Using Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 750 Ti (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "import csv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Bringing in the data and cleaning it up\n",
    "train = 'training.csv'\n",
    "test = 'test.csv'\n",
    "df = pd.read_csv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1687   NaN\n",
       "1834   NaN\n",
       "1866   NaN\n",
       "1938   NaN\n",
       "2100   NaN\n",
       "2137   NaN\n",
       "2153   NaN\n",
       "2175   NaN\n",
       "2186   NaN\n",
       "2239   NaN\n",
       "Name: left_eye_center_x, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['left_eye_center_x'].isnull(),'left_eye_center_x']\n",
    "## A total of 10 are null in case of the left_eye_center_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2140 entries, 0 to 2283\n",
      "Data columns (total 31 columns):\n",
      "left_eye_center_x            2140 non-null float64\n",
      "left_eye_center_y            2140 non-null float64\n",
      "right_eye_center_x           2140 non-null float64\n",
      "right_eye_center_y           2140 non-null float64\n",
      "left_eye_inner_corner_x      2140 non-null float64\n",
      "left_eye_inner_corner_y      2140 non-null float64\n",
      "left_eye_outer_corner_x      2140 non-null float64\n",
      "left_eye_outer_corner_y      2140 non-null float64\n",
      "right_eye_inner_corner_x     2140 non-null float64\n",
      "right_eye_inner_corner_y     2140 non-null float64\n",
      "right_eye_outer_corner_x     2140 non-null float64\n",
      "right_eye_outer_corner_y     2140 non-null float64\n",
      "left_eyebrow_inner_end_x     2140 non-null float64\n",
      "left_eyebrow_inner_end_y     2140 non-null float64\n",
      "left_eyebrow_outer_end_x     2140 non-null float64\n",
      "left_eyebrow_outer_end_y     2140 non-null float64\n",
      "right_eyebrow_inner_end_x    2140 non-null float64\n",
      "right_eyebrow_inner_end_y    2140 non-null float64\n",
      "right_eyebrow_outer_end_x    2140 non-null float64\n",
      "right_eyebrow_outer_end_y    2140 non-null float64\n",
      "nose_tip_x                   2140 non-null float64\n",
      "nose_tip_y                   2140 non-null float64\n",
      "mouth_left_corner_x          2140 non-null float64\n",
      "mouth_left_corner_y          2140 non-null float64\n",
      "mouth_right_corner_x         2140 non-null float64\n",
      "mouth_right_corner_y         2140 non-null float64\n",
      "mouth_center_top_lip_x       2140 non-null float64\n",
      "mouth_center_top_lip_y       2140 non-null float64\n",
      "mouth_center_bottom_lip_x    2140 non-null float64\n",
      "mouth_center_bottom_lip_y    2140 non-null float64\n",
      "Image                        2140 non-null object\n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 535.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    238 236 237 238 240 240 239 241 241 243 240 23...\n",
       "1    219 215 204 196 204 211 212 200 180 168 178 19...\n",
       "2    144 142 159 180 188 188 184 180 167 132 84 59 ...\n",
       "3    193 192 193 194 194 194 193 192 168 111 50 12 ...\n",
       "4    147 148 160 196 215 214 216 217 219 220 206 18...\n",
       "Name: Image, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Image'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.93333334  0.9254902   0.92941177 ...,  0.27450982  0.29411766\n",
      "   0.35294119]\n",
      " [ 0.85882354  0.84313726  0.80000001 ...,  0.00392157  0.00392157\n",
      "   0.00392157]\n",
      " [ 0.56470591  0.55686277  0.62352943 ...,  0.30588236  0.30588236\n",
      "   0.3019608 ]\n",
      " ..., \n",
      " [ 0.12156863  0.15686275  0.18431373 ...,  0.15294118  0.2         0.29411766]\n",
      " [ 0.02745098  0.00392157  0.01960784 ...,  0.7019608   0.69411767\n",
      "   0.22352941]\n",
      " [ 0.26666668  0.07450981  0.07450981 ...,  0.49019608  0.48627451\n",
      "   0.46666667]]\n",
      "(2140, 9216)\n"
     ]
    }
   ],
   "source": [
    "df['Image'].head()\n",
    "X = np.vstack(df['Image'].values)/255\n",
    "X = X.astype(np.float32)\n",
    "print X\n",
    "print np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 9216)\n",
      "(940, 9216)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:1200,:]\n",
    "X_cv = X[1200:,:]\n",
    "print np.shape(X_train)\n",
    "print np.shape(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 30)\n"
     ]
    }
   ],
   "source": [
    "y = df[df.columns[:-1]].values\n",
    "y = y.astype(np.float32)\n",
    "print np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 30)\n",
      "(940, 30)\n"
     ]
    }
   ],
   "source": [
    "y_train = y[:1200,:]\n",
    "y_cv = y[1200:,:]\n",
    "print np.shape(y_train)\n",
    "print np.shape(y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Dense(32,input_dim = 9216),\n",
    "        Activation('relu'),\n",
    "        Dense(100),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(30),\n",
    "        Activation('relu'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('/home/najeeb/Desktop/Dataset/Facial_Keypoints_Recog/Weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa48c137fd0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,nb_epoch=400,batch_size=32,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('/home/najeeb/Desktop/Dataset/Facial_Keypoints_Recog/Weights.hdf5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_4 (Dense)                    (None, 32)          294944      dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)          (None, 32)          0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                    (None, 100)         3300        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)          (None, 100)         0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 100)         0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                    (None, 30)          3030        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)          (None, 30)          0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 301274\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking model input: expected convolution2d_input_1 to have 4 dimensions, but got array with shape (940, 9216)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3cb5f9bd2539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/karpathy/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/karpathy/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                                                            \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m                                                            batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[1;31m# prepare inputs, delegate logic to _test_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/karpathy/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[0;32m    919\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                                    exception_prefix='model input')\n\u001b[0m\u001b[0;32m    922\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[0;32m    923\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/karpathy/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[0;32m     91\u001b[0m                                 \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                                 \u001b[1;34m' dimensions, but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                                 str(array.shape))\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Error when checking model input: expected convolution2d_input_1 to have 4 dimensions, but got array with shape (940, 9216)"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_cv,y_cv,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4765.4099006815159, 0.52340425531914891]\n"
     ]
    }
   ],
   "source": [
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1783 entries, 1 to 1783\n",
      "Data columns (total 1 columns):\n",
      "Image    1783 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 27.9+ KB\n"
     ]
    }
   ],
   "source": [
    "## Bringing in the test set\n",
    "df_test = pd.read_csv(test,index_col = 0)\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1783 entries, 1 to 1783\n",
      "Data columns (total 1 columns):\n",
      "Image    1783 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 27.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182 183 182 182 180 180 176 169 156 137 124 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177 176 174 170 169 169 168 166 166 166 161 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176 174 174 175 174 174 176 176 175 171 165 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50 47 44 101 144 149 120 58 48 42 35 35 37 39 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Image\n",
       "ImageId                                                   \n",
       "1        182 183 182 182 180 180 176 169 156 137 124 10...\n",
       "2        76 87 81 72 65 59 64 76 69 42 31 38 49 58 58 4...\n",
       "3        177 176 174 170 169 169 168 166 166 166 161 14...\n",
       "4        176 174 174 175 174 174 176 176 175 171 165 15...\n",
       "5        50 47 44 101 144 149 120 58 48 42 35 35 37 39 ..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageId\n",
       "1       [182.0, 183.0, 182.0, 182.0, 180.0, 180.0, 176...\n",
       "2       [76.0, 87.0, 81.0, 72.0, 65.0, 59.0, 64.0, 76....\n",
       "3       [177.0, 176.0, 174.0, 170.0, 169.0, 169.0, 168...\n",
       "4       [176.0, 174.0, 174.0, 175.0, 174.0, 174.0, 176...\n",
       "5       [50.0, 47.0, 44.0, 101.0, 144.0, 149.0, 120.0,...\n",
       "6       [177.0, 177.0, 177.0, 171.0, 142.0, 115.0, 97....\n",
       "7       [77.0, 55.0, 44.0, 56.0, 58.0, 61.0, 67.0, 66....\n",
       "8       [156.0, 160.0, 162.0, 166.0, 150.0, 114.0, 97....\n",
       "9       [230.0, 230.0, 231.0, 231.0, 231.0, 231.0, 231...\n",
       "10      [132.0, 129.0, 126.0, 128.0, 146.0, 163.0, 170...\n",
       "11      [182.0, 182.0, 182.0, 182.0, 182.0, 181.0, 183...\n",
       "12      [207.0, 205.0, 204.0, 202.0, 205.0, 197.0, 184...\n",
       "13      [121.0, 83.0, 58.0, 41.0, 37.0, 36.0, 33.0, 33...\n",
       "14      [89.0, 60.0, 63.0, 65.0, 65.0, 84.0, 64.0, 35....\n",
       "15      [88.0, 112.0, 132.0, 132.0, 133.0, 135.0, 131....\n",
       "16      [153.0, 153.0, 155.0, 156.0, 155.0, 154.0, 153...\n",
       "17      [97.0, 101.0, 98.0, 92.0, 91.0, 91.0, 95.0, 99...\n",
       "18      [253.0, 252.0, 254.0, 236.0, 173.0, 103.0, 67....\n",
       "19      [244.0, 245.0, 250.0, 183.0, 82.0, 64.0, 60.0,...\n",
       "20      [121.0, 122.0, 124.0, 123.0, 133.0, 157.0, 163...\n",
       "21      [252.0, 252.0, 251.0, 249.0, 251.0, 249.0, 246...\n",
       "22      [178.0, 180.0, 181.0, 182.0, 182.0, 181.0, 185...\n",
       "23      [170.0, 170.0, 167.0, 170.0, 168.0, 170.0, 168...\n",
       "24      [202.0, 202.0, 205.0, 204.0, 206.0, 206.0, 206...\n",
       "25      [119.0, 116.0, 106.0, 98.0, 88.0, 70.0, 55.0, ...\n",
       "26      [217.0, 212.0, 133.0, 36.0, 20.0, 27.0, 20.0, ...\n",
       "27      [115.0, 106.0, 100.0, 89.0, 83.0, 85.0, 84.0, ...\n",
       "28      [178.0, 179.0, 181.0, 178.0, 176.0, 172.0, 166...\n",
       "29      [171.0, 158.0, 97.0, 49.0, 43.0, 38.0, 34.0, 2...\n",
       "30      [254.0, 254.0, 254.0, 242.0, 180.0, 118.0, 92....\n",
       "                              ...                        \n",
       "1754    [53.0, 54.0, 51.0, 50.0, 49.0, 52.0, 53.0, 49....\n",
       "1755    [60.0, 61.0, 65.0, 69.0, 75.0, 87.0, 105.0, 11...\n",
       "1756    [66.0, 67.0, 69.0, 71.0, 72.0, 73.0, 73.0, 69....\n",
       "1757    [133.0, 129.0, 129.0, 129.0, 130.0, 133.0, 133...\n",
       "1758    [191.0, 223.0, 233.0, 248.0, 250.0, 231.0, 229...\n",
       "1759    [169.0, 154.0, 142.0, 146.0, 127.0, 114.0, 107...\n",
       "1760    [164.0, 164.0, 164.0, 164.0, 162.0, 159.0, 160...\n",
       "1761    [46.0, 61.0, 78.0, 92.0, 84.0, 71.0, 53.0, 62....\n",
       "1762    [111.0, 124.0, 129.0, 121.0, 105.0, 92.0, 93.0...\n",
       "1763    [9.0, 11.0, 9.0, 8.0, 7.0, 11.0, 9.0, 6.0, 8.0...\n",
       "1764    [26.0, 23.0, 18.0, 17.0, 16.0, 17.0, 17.0, 16....\n",
       "1765    [115.0, 94.0, 49.0, 55.0, 87.0, 101.0, 105.0, ...\n",
       "1766    [195.0, 200.0, 165.0, 145.0, 157.0, 140.0, 75....\n",
       "1767    [182.0, 185.0, 178.0, 190.0, 173.0, 161.0, 164...\n",
       "1768    [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...\n",
       "1769    [150.0, 170.0, 177.0, 180.0, 171.0, 181.0, 175...\n",
       "1770    [129.0, 179.0, 157.0, 123.0, 98.0, 89.0, 96.0,...\n",
       "1771    [59.0, 59.0, 64.0, 59.0, 57.0, 57.0, 59.0, 58....\n",
       "1772    [130.0, 120.0, 110.0, 111.0, 126.0, 137.0, 110...\n",
       "1773    [129.0, 122.0, 91.0, 64.0, 65.0, 73.0, 69.0, 6...\n",
       "1774    [213.0, 213.0, 212.0, 213.0, 213.0, 212.0, 188...\n",
       "1775    [123.0, 131.0, 106.0, 54.0, 24.0, 20.0, 17.0, ...\n",
       "1776    [142.0, 131.0, 114.0, 108.0, 107.0, 125.0, 145...\n",
       "1777    [71.0, 71.0, 70.0, 69.0, 69.0, 70.0, 74.0, 77....\n",
       "1778    [100.0, 106.0, 105.0, 106.0, 105.0, 104.0, 104...\n",
       "1779    [101.0, 101.0, 101.0, 100.0, 100.0, 97.0, 97.0...\n",
       "1780    [201.0, 191.0, 171.0, 158.0, 145.0, 140.0, 136...\n",
       "1781    [28.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34....\n",
       "1782    [104.0, 95.0, 71.0, 57.0, 46.0, 52.0, 65.0, 70...\n",
       "1783    [63.0, 61.0, 64.0, 66.0, 66.0, 64.0, 65.0, 70....\n",
       "Name: Image, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Image'] = df_test['Image'].apply(lambda im: np.fromstring(im,sep=' '))\n",
    "df_test['Image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.vstack(df_test['Image'].values)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71372549  0.71764706  0.71372549 ...,  0.03137255  0.01960784\n",
      "   0.01960784]\n",
      " [ 0.29803922  0.34117647  0.31764706 ...,  0.89411765  0.82745098\n",
      "   0.65882353]\n",
      " [ 0.69411765  0.69019608  0.68235294 ...,  0.00392157  0.00392157\n",
      "   0.00392157]\n",
      " ..., \n",
      " [ 0.10980392  0.10980392  0.11372549 ...,  0.30196078  0.30588235\n",
      "   0.30588235]\n",
      " [ 0.40784314  0.37254902  0.27843137 ...,  0.56470588  0.59215686\n",
      "   0.62352941]\n",
      " [ 0.24705882  0.23921569  0.25098039 ...,  0.44313725  0.43921569\n",
      "   0.44313725]]\n"
     ]
    }
   ],
   "source": [
    "print X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yPred = model.predict(X_test,batch_size=32,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.05997181   7.81734133   5.98451424 ...,  14.54801846  10.20882607\n",
      "   17.73294449]\n",
      " [  9.59679127   5.1310401    3.96576643 ...,  10.67988396   7.13038301\n",
      "   12.54106331]\n",
      " [ 17.5809536    9.73304844   8.34363651 ...,  19.10345459  13.63756752\n",
      "   22.02163315]\n",
      " ..., \n",
      " [  7.81345463   4.07394934   3.45347261 ...,   8.14753437   5.3670783\n",
      "    9.71312904]\n",
      " [ 10.09251308   5.88532495   4.4658947  ...,  10.29162216   7.48822737\n",
      "   12.74537945]\n",
      " [  7.54152155   4.34356165   3.37557602 ...,   8.11832333   5.26921129\n",
      "    9.53826237]]\n",
      "(1783, 30)\n"
     ]
    }
   ],
   "source": [
    "print yPred\n",
    "print np.shape(yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(np.shape(yPred)[0]):\n",
    "    for j in range(np.shape(yPred)[1]):\n",
    "        if yPred[i][j] < 0:\n",
    "            yPred[i][j] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Takes a long time to run so use a GPU\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 9216)\n",
      "(1200, 30)\n",
      "(1200, 1, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "## Reshaping the data into 3D format\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],1,96,96))\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "## First Convolution layer\n",
    "model.add(Convolution2D(32,3,3,border_mode = 'valid', input_shape = (1,96,96)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32,3,3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "## Second Convolution Layer\n",
    "model.add(Convolution2D(64,3,3,border_mode = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64,3,3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "## Adding the fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## Addding the final ouput layer\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',optimizer = 'adagrad',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('Weights_CNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 5s - loss: 18505.2442 - acc: 0.5933     \n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 5s - loss: 128.1210 - acc: 0.4617     \n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 5s - loss: 89.1057 - acc: 0.4550     \n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 5s - loss: 88.5229 - acc: 0.4700     \n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 5s - loss: 77.2224 - acc: 0.4950     \n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 5s - loss: 74.2620 - acc: 0.5033     \n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 5s - loss: 68.6746 - acc: 0.5242     \n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 6s - loss: 66.2490 - acc: 0.5192     \n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - 5s - loss: 65.3634 - acc: 0.5425     \n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 5s - loss: 64.4533 - acc: 0.5417     \n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 5s - loss: 66.3506 - acc: 0.5350     \n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 5s - loss: 58.2733 - acc: 0.5742     \n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 5s - loss: 60.4386 - acc: 0.5667     \n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 5s - loss: 57.0882 - acc: 0.5808     \n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 6s - loss: 56.3907 - acc: 0.5792     \n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - 5s - loss: 57.2893 - acc: 0.5692     \n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 5s - loss: 56.6201 - acc: 0.5658     \n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 5s - loss: 54.3918 - acc: 0.6117     \n",
      "Epoch 19/50\n",
      "1200/1200 [==============================] - 6s - loss: 57.1315 - acc: 0.6125     \n",
      "Epoch 20/50\n",
      "1200/1200 [==============================] - 6s - loss: 52.0538 - acc: 0.5883     \n",
      "Epoch 21/50\n",
      "1200/1200 [==============================] - 6s - loss: 52.2471 - acc: 0.5892     \n",
      "Epoch 22/50\n",
      "1200/1200 [==============================] - 6s - loss: 50.6626 - acc: 0.6117     \n",
      "Epoch 23/50\n",
      "1200/1200 [==============================] - 6s - loss: 50.8294 - acc: 0.5925     \n",
      "Epoch 24/50\n",
      "1200/1200 [==============================] - 6s - loss: 47.8153 - acc: 0.6275     \n",
      "Epoch 25/50\n",
      "1200/1200 [==============================] - 6s - loss: 51.3735 - acc: 0.6183     \n",
      "Epoch 26/50\n",
      "1200/1200 [==============================] - 6s - loss: 49.4699 - acc: 0.6233     \n",
      "Epoch 27/50\n",
      "1200/1200 [==============================] - 6s - loss: 48.8160 - acc: 0.6275     \n",
      "Epoch 28/50\n",
      "1200/1200 [==============================] - 6s - loss: 46.6328 - acc: 0.6217     \n",
      "Epoch 29/50\n",
      "1200/1200 [==============================] - 6s - loss: 47.7847 - acc: 0.6083     \n",
      "Epoch 30/50\n",
      "1200/1200 [==============================] - 6s - loss: 48.3017 - acc: 0.6242     \n",
      "Epoch 31/50\n",
      "1200/1200 [==============================] - 6s - loss: 50.5656 - acc: 0.6225     \n",
      "Epoch 32/50\n",
      "1200/1200 [==============================] - 6s - loss: 48.5439 - acc: 0.6317     \n",
      "Epoch 33/50\n",
      "1200/1200 [==============================] - 6s - loss: 47.5785 - acc: 0.6325     \n",
      "Epoch 34/50\n",
      "1200/1200 [==============================] - 6s - loss: 46.8795 - acc: 0.6650     \n",
      "Epoch 35/50\n",
      "1200/1200 [==============================] - 6s - loss: 46.7889 - acc: 0.6517     \n",
      "Epoch 36/50\n",
      "1200/1200 [==============================] - 6s - loss: 48.4407 - acc: 0.6558     \n",
      "Epoch 37/50\n",
      "1200/1200 [==============================] - 6s - loss: 46.2954 - acc: 0.6467     \n",
      "Epoch 38/50\n",
      "1200/1200 [==============================] - 6s - loss: 46.0766 - acc: 0.6400     \n",
      "Epoch 39/50\n",
      "1200/1200 [==============================] - 6s - loss: 46.5602 - acc: 0.6450     \n",
      "Epoch 40/50\n",
      "1200/1200 [==============================] - 6s - loss: 44.2415 - acc: 0.6467     \n",
      "Epoch 41/50\n",
      "1200/1200 [==============================] - 6s - loss: 45.6531 - acc: 0.6350     \n",
      "Epoch 42/50\n",
      "1200/1200 [==============================] - 6s - loss: 44.8587 - acc: 0.6350     \n",
      "Epoch 43/50\n",
      "1200/1200 [==============================] - 6s - loss: 46.2857 - acc: 0.6608     \n",
      "Epoch 44/50\n",
      "1200/1200 [==============================] - 6s - loss: 44.4219 - acc: 0.6733     \n",
      "Epoch 45/50\n",
      "1200/1200 [==============================] - 6s - loss: 44.0801 - acc: 0.6542     \n",
      "Epoch 46/50\n",
      "1200/1200 [==============================] - 5s - loss: 45.2650 - acc: 0.6483     \n",
      "Epoch 47/50\n",
      "1200/1200 [==============================] - 5s - loss: 43.0631 - acc: 0.6642     \n",
      "Epoch 48/50\n",
      "1200/1200 [==============================] - 6s - loss: 44.7383 - acc: 0.6650     \n",
      "Epoch 49/50\n",
      "1200/1200 [==============================] - 6s - loss: 45.5815 - acc: 0.6508     \n",
      "Epoch 50/50\n",
      "1200/1200 [==============================] - 5s - loss: 44.0418 - acc: 0.6758     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05e929b0d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,nb_epoch=50,batch_size=32,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Weights_CNN.hdf5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('Weights_CNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(940, 1, 96, 96)\n",
      "(940, 30)\n",
      "(940, 1, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "print X_cv.shape\n",
    "print y_cv.shape\n",
    "X_cv = np.reshape(X_cv,(X_cv.shape[0],1,96,96))\n",
    "print X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940/940 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_cv,y_cv,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.143131905413689, 0.52553191489361706]\n"
     ]
    }
   ],
   "source": [
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.vstack(df_test['Image'].values)/255\n",
    "X_test = np.reshape(X_test,(X_test.shape[0],1,96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1783/1783 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "yPred = model.predict(X_test,batch_size = 32,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60.24824524  33.65006638  27.05023003 ...,  64.10475159  43.48781204\n",
      "   76.24269104]\n",
      " [ 63.12611008  35.42623901  28.45466423 ...,  67.37026978  45.73833084\n",
      "   79.98352814]\n",
      " [ 62.29702759  35.07566452  28.22402763 ...,  66.61660767  45.31272507\n",
      "   78.83598328]\n",
      " ..., \n",
      " [ 58.62841797  33.05129242  26.5137043  ...,  62.38238144  42.5090332\n",
      "   74.02697754]\n",
      " [ 59.52952194  33.33998871  26.77518082 ...,  63.24361038  43.01625443\n",
      "   75.15684509]\n",
      " [ 63.23072433  35.15843964  28.12704277 ...,  66.98067474  45.45367432\n",
      "   80.3243103 ]]\n"
     ]
    }
   ],
   "source": [
    "print yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in yPred:\n",
    "    for value in row:\n",
    "        if value < 0.0 or value > 95.0:\n",
    "            value = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the data into the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Writing the data into a csv file\n",
    "fp = open('submission.csv',\"w\")\n",
    "p = csv.writer(fp)\n",
    "fp_lookup = open('IdLookupTable.csv',\"r\")\n",
    "lookup = csv.reader(fp_lookup)\n",
    "header = lookup.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for feature in df.columns[:]:\n",
    "    features.append(feature)\n",
    "features.pop(-1)\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating a dictionary of features\n",
    "h = dict((w,i) for i,w in enumerate(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.writerow(['RowId','Location'])\n",
    "for row in lookup:\n",
    "    p.writerow([row[0],yPred[int(row[1]) - 1][h[row[2]]]])\n",
    "fp.close()\n",
    "fp_lookup.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
