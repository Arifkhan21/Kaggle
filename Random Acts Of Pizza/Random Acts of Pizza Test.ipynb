{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Acts Of Pizza\n",
    "### Applying Topic Modelling On Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_json('../../Dataset/Random Acts Of Pizza/train.json')\n",
    "data_test = pd.read_json('../../Dataset/Random Acts Of Pizza/test.json')\n",
    "y = data_train.pop('requester_received_pizza')\n",
    "request_id = data_test['request_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_present = []\n",
    "for i in data_train.columns:\n",
    "    if i not in data_test.columns:\n",
    "        not_present.append(i)\n",
    "data_train.drop(labels=not_present,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5671, 31)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Combining the training and testing data\n",
    "\n",
    "data = pd.concat([data_train,data_test])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5671 entries, 0 to 1630\n",
      "Data columns (total 17 columns):\n",
      "giver_username_if_known                               5671 non-null object\n",
      "request_id                                            5671 non-null object\n",
      "request_text_edit_aware                               5671 non-null object\n",
      "request_title                                         5671 non-null object\n",
      "requester_account_age_in_days_at_request              5671 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_request    5671 non-null float64\n",
      "requester_number_of_comments_at_request               5671 non-null int64\n",
      "requester_number_of_comments_in_raop_at_request       5671 non-null int64\n",
      "requester_number_of_posts_at_request                  5671 non-null int64\n",
      "requester_number_of_posts_on_raop_at_request          5671 non-null int64\n",
      "requester_number_of_subreddits_at_request             5671 non-null int64\n",
      "requester_subreddits_at_request                       5671 non-null object\n",
      "requester_upvotes_minus_downvotes_at_request          5671 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_request           5671 non-null int64\n",
      "requester_username                                    5671 non-null object\n",
      "unix_timestamp_of_request                             5671 non-null int64\n",
      "unix_timestamp_of_request_utc                         5671 non-null int64\n",
      "dtypes: float64(2), int64(9), object(6)\n",
      "memory usage: 797.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
    "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def applyLDA(data_samples):\n",
    "    \n",
    "    # Use tf-idf features for NMF.\n",
    "    print(\"Extracting tf features for LDA...\")\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                                stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(data_samples)\n",
    "    \n",
    "    # Fit the NMF model\n",
    "    print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "    lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "    lda.fit(tf)\n",
    "    return lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyNMF(data_samples):\n",
    "    print(\"Extracting tf-idf features for NMF...\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "    print(\"Fitting the NMF model with tf-idf features,\"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "    nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "    return nmf.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Removing stopwords from the comments\n",
    "\n",
    "data['request_text_edit_aware'] = map(lambda x: ' '.join([i for i in x.lower().split(' ') if i not in stopwords.words('english')]),\\\n",
    "    data['request_text_edit_aware'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n",
      "(5671, 10)\n"
     ]
    }
   ],
   "source": [
    "## Applying Non Negative Matrix Factorisation on Request Posts\n",
    "\n",
    "topics = applyNMF(data['request_text_edit_aware'])\n",
    "print(topics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.asarray([np.argmax(row) for row in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['topics'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Changing the \"giver_username\" column to 0/1\n",
    "\n",
    "data.giver_username_if_known = data.giver_username_if_known.map({'N/A':0})\n",
    "data.giver_username_if_known.fillna(1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.giver_username_if_known.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n"
     ]
    }
   ],
   "source": [
    "## Applying Non Negative Matrix Factorisation on Request Title\n",
    "\n",
    "title_topics = applyNMF(parent_data['request_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_topics_max = np.asarray([np.argmax(i) for i in title_topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['request_title'] = title_topics_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Adding the length of the request as the feature\n",
    "\n",
    "data['request_length'] = [len(x) for x in parent_data['request_text_edit_aware']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddits = map(lambda x: ' '.join(x),parent_data['requester_subreddits_at_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "Fitting the NMF model with tf-idf features,n_samples=2000 and n_features=1000...\n"
     ]
    }
   ],
   "source": [
    "## Applying NMF on Subreddits\n",
    "\n",
    "subreddits_topics = applyNMF(subreddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.asarray([np.argmax(row) for row in subreddits_topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['subreddit_topics'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = dict()\n",
    "for i in range(parent_data.shape[0]):\n",
    "    if parent_data.iloc[i,-7] == True:\n",
    "        for subreddit in parent_data.iloc[i,-6]:\n",
    "            try:\n",
    "                count[subreddit] += 1\n",
    "            except:\n",
    "                count[subreddit] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_series = pd.Series(count.values(),index = count.keys())\n",
    "count_series.sort_values(ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddits = set(count_series[count_series > 300].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Counting the important subreddit and checking their presence\n",
    "\n",
    "data['subreddit_count'] = map(lambda x: len(set(x).intersection(subreddits)),\\\n",
    "                              parent_data['requester_subreddits_at_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5671 entries, 0 to 1630\n",
      "Data columns (total 17 columns):\n",
      "giver_username_if_known                               5671 non-null float64\n",
      "request_title                                         5671 non-null int64\n",
      "requester_account_age_in_days_at_request              5671 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_request    5671 non-null float64\n",
      "requester_number_of_comments_at_request               5671 non-null int64\n",
      "requester_number_of_comments_in_raop_at_request       5671 non-null int64\n",
      "requester_number_of_posts_at_request                  5671 non-null int64\n",
      "requester_number_of_posts_on_raop_at_request          5671 non-null int64\n",
      "requester_number_of_subreddits_at_request             5671 non-null int64\n",
      "requester_upvotes_minus_downvotes_at_request          5671 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_request           5671 non-null int64\n",
      "unix_timestamp_of_request                             5671 non-null int64\n",
      "unix_timestamp_of_request_utc                         5671 non-null int64\n",
      "topics                                                5671 non-null int64\n",
      "request_length                                        5671 non-null int64\n",
      "subreddit_topics                                      5671 non-null int64\n",
      "subreddit_count                                       5671 non-null int64\n",
      "dtypes: float64(3), int64(14)\n",
      "memory usage: 797.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.drop(labels=[i for i in data.columns if data[i].dtype == 'object'],axis=1,inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[0:y.shape[0],:]\n",
    "print X.shape[0] == data_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "test = data.iloc[y.shape[0]:,:]\n",
    "print test.shape[0] == data_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: requester_received_pizza, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.map({False:0,True:1})\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2828, 17) (2828,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)\n",
    "xgb.set_params(max_depth=10,n_estimators=200)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 2) (1212, 2)\n"
     ]
    }
   ],
   "source": [
    "test_rfc = rfc.predict_proba(X_test)\n",
    "test_xgb  = xgb.predict_proba(X_test)\n",
    "print test_rfc.shape,test_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum score: 0.763074619379\n",
      "XGB Weight: 0.2\n",
      "RFC Weight: 0.8\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "xgb_weight,rfc_weight=0,0\n",
    "for i in np.arange(0.9,0.1,-0.1):\n",
    "    score = roc_auc_score(y_test,(i*test_xgb+(1-i)*test_rfc)[:,1])\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        xgb_weight = i\n",
    "        rfc_weight = 1-i\n",
    "print 'Maximum score: {}'.format(max_score)\n",
    "print 'XGB Weight: {}'.format(xgb_weight)\n",
    "print 'RFC Weight: {}'.format(rfc_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rfc = rfc.predict_proba(test)\n",
    "test_xgb  = xgb.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631,)\n"
     ]
    }
   ],
   "source": [
    "testPred = np.asarray([np.argmax(row) for row in ((xgb_weight*test_xgb+(rfc_weight)*test_rfc))])\n",
    "print testPred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = open(\"submission.csv\",'wb')\n",
    "p = csv.writer(fp)\n",
    "p.writerow(['request_id','requester_received_pizza'])\n",
    "for i in range(len(testPred)):\n",
    "    p.writerow([request_id[i],testPred[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
